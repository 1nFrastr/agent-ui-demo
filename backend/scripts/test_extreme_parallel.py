#!/usr/bin/env python3
"""
æè‡´å¹¶è¡ŒåŒ–æµ‹è¯•ï¼šçœŸæ­£çš„åŒæ—¶å¼€å§‹
"""

import asyncio
import time
import logging
import sys
import os
import httpx
from typing import List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from app.tools.web_content import WebContentTool
from app.config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# æµ‹è¯•URLåˆ—è¡¨
TEST_URLS = [
    "https://zh.wikipedia.org/wiki/Python",
    "https://docs.python.org/3/",
    "https://fastapi.tiangolo.com/"
]

class ExtremeParallelTest:
    def __init__(self):
        # é¢„å…ˆåˆ›å»ºå…±äº«å®¢æˆ·ç«¯
        self.shared_client = None
    
    async def init_shared_client(self):
        """åˆå§‹åŒ–å…±äº«HTTPå®¢æˆ·ç«¯"""
        self.shared_client = httpx.AsyncClient(
            timeout=settings.request_timeout,
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            },
            limits=httpx.Limits(max_keepalive_connections=20, max_connections=100)
        )
        logger.info("ğŸ”§ å…±äº«HTTPå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    async def close_shared_client(self):
        """å…³é—­å…±äº«å®¢æˆ·ç«¯"""
        if self.shared_client:
            await self.shared_client.aclose()
    
    async def test_extreme_parallel_v1(self, urls: List[str]) -> tuple:
        """æè‡´å¹¶è¡ŒV1ï¼šé¢„åˆå§‹åŒ–+åŒæ—¶åˆ›å»ºä»»åŠ¡"""
        logger.info("ğŸš€ å¼€å§‹æè‡´å¹¶è¡Œæµ‹è¯•V1 (é¢„åˆå§‹åŒ–)...")
        
        # ç¡®ä¿å…±äº«å®¢æˆ·ç«¯å·²åˆå§‹åŒ–
        await self.init_shared_client()
        
        start_time = time.time()
        
        async def extract_with_shared_client(url: str, index: int):
            logger.info(f"[æè‡´V1] ç«‹å³å¼€å§‹å¤„ç†URL {index}: {url}")
            try:
                # ç›´æ¥ä½¿ç”¨é¢„åˆå§‹åŒ–çš„å®¢æˆ·ç«¯
                response = await self.shared_client.get(url)
                response.raise_for_status()
                content_length = len(response.text)
                logger.info(f"[æè‡´V1] å®ŒæˆURL {index}: {url} ({content_length}å­—ç¬¦)")
                return {"url": url, "content_length": content_length, "status": "success"}
            except Exception as e:
                logger.error(f"[æè‡´V1] å¤±è´¥URL {index}: {e}")
                return {"url": url, "error": str(e), "status": "failed"}
        
        # ç«‹å³åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [
            extract_with_shared_client(url, i+1) 
            for i, url in enumerate(urls)
        ]
        
        logger.info(f"ğŸ“‹ å·²åˆ›å»º{len(tasks)}ä¸ªå¹¶å‘ä»»åŠ¡ï¼Œå¼€å§‹æ‰§è¡Œ...")
        
        # çœŸæ­£çš„å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        total_time = time.time() - start_time
        logger.info(f"ğŸ æè‡´å¹¶è¡ŒV1å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        await self.close_shared_client()
        return results, total_time
    
    async def test_extreme_parallel_v2(self, urls: List[str]) -> tuple:
        """æè‡´å¹¶è¡ŒV2ï¼šä½¿ç”¨asyncio.create_taskç«‹å³å¯åŠ¨"""
        logger.info("ğŸš€ å¼€å§‹æè‡´å¹¶è¡Œæµ‹è¯•V2 (create_task)...")
        
        await self.init_shared_client()
        start_time = time.time()
        
        async def extract_immediate(url: str, index: int):
            # è®°å½•çœŸæ­£çš„å¼€å§‹æ—¶é—´
            task_start = time.time()
            logger.info(f"[æè‡´V2] ç«‹å³å¼€å§‹å¤„ç†URL {index}: {url} (ä»»åŠ¡å¯åŠ¨æ—¶é—´: {task_start - start_time:.2f}s)")
            
            try:
                response = await self.shared_client.get(url)
                response.raise_for_status()
                content_length = len(response.text)
                task_duration = time.time() - task_start
                logger.info(f"[æè‡´V2] å®ŒæˆURL {index}: {url} (ä»»åŠ¡è€—æ—¶: {task_duration:.2f}s)")
                return {"url": url, "content_length": content_length, "status": "success"}
            except Exception as e:
                task_duration = time.time() - task_start
                logger.error(f"[æè‡´V2] å¤±è´¥URL {index}: {e} (ä»»åŠ¡è€—æ—¶: {task_duration:.2f}s)")
                return {"url": url, "error": str(e), "status": "failed"}
        
        # ä½¿ç”¨create_taskç«‹å³å¯åŠ¨æ‰€æœ‰ä»»åŠ¡
        tasks = []
        for i, url in enumerate(urls):
            task = asyncio.create_task(extract_immediate(url, i+1))
            tasks.append(task)
            logger.info(f"ğŸ“¤ ä»»åŠ¡{i+1}å·²å¯åŠ¨")
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        total_time = time.time() - start_time
        logger.info(f"ğŸ æè‡´å¹¶è¡ŒV2å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        await self.close_shared_client()
        return results, total_time
    
    async def test_extreme_parallel_v3(self, urls: List[str]) -> tuple:
        """æè‡´å¹¶è¡ŒV3ï¼šä½¿ç”¨åŸå§‹httpxç›´æ¥å¹¶å‘"""
        logger.info("ğŸš€ å¼€å§‹æè‡´å¹¶è¡Œæµ‹è¯•V3 (åŸå§‹httpx)...")
        
        start_time = time.time()
        
        async def raw_httpx_fetch(url: str, index: int):
            task_start = time.time()
            logger.info(f"[æè‡´V3] ç«‹å³å¼€å§‹å¤„ç†URL {index}: {url} (å¯åŠ¨æ—¶é—´: {task_start - start_time:.3f}s)")
            
            async with httpx.AsyncClient(
                timeout=10.0,
                limits=httpx.Limits(max_keepalive_connections=20, max_connections=100)
            ) as client:
                try:
                    response = await client.get(url)
                    response.raise_for_status()
                    content_length = len(response.text)
                    task_duration = time.time() - task_start
                    logger.info(f"[æè‡´V3] å®ŒæˆURL {index}: {url} (è€—æ—¶: {task_duration:.2f}s)")
                    return {"url": url, "content_length": content_length, "status": "success"}
                except Exception as e:
                    task_duration = time.time() - task_start
                    logger.error(f"[æè‡´V3] å¤±è´¥URL {index}: {e} (è€—æ—¶: {task_duration:.2f}s)")
                    return {"url": url, "error": str(e), "status": "failed"}
        
        # ç«‹å³åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [raw_httpx_fetch(url, i+1) for i, url in enumerate(urls)]
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        total_time = time.time() - start_time
        logger.info(f"ğŸ æè‡´å¹¶è¡ŒV3å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        return results, total_time

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æè‡´å¹¶è¡ŒåŒ–æµ‹è¯•")
    print("=" * 50)
    
    test_runner = ExtremeParallelTest()
    test_urls = TEST_URLS
    
    print(f"ğŸ“‹ æµ‹è¯•URLåˆ—è¡¨ ({len(test_urls)}ä¸ª):")
    for i, url in enumerate(test_urls, 1):
        print(f"   {i}. {url}")
    print()
    
    try:
        # æµ‹è¯•1ï¼šé¢„åˆå§‹åŒ–å…±äº«å®¢æˆ·ç«¯
        v1_results, v1_time = await test_runner.test_extreme_parallel_v1(test_urls)
        print(f"\nğŸ“Š æè‡´å¹¶è¡ŒV1ç»“æœ: {v1_time:.2f}ç§’")
        
        print("\n" + "="*30)
        
        # æµ‹è¯•2ï¼šcreate_taskç«‹å³å¯åŠ¨
        v2_results, v2_time = await test_runner.test_extreme_parallel_v2(test_urls)
        print(f"\nğŸ“Š æè‡´å¹¶è¡ŒV2ç»“æœ: {v2_time:.2f}ç§’")
        
        print("\n" + "="*30)
        
        # æµ‹è¯•3ï¼šåŸå§‹httpx
        v3_results, v3_time = await test_runner.test_extreme_parallel_v3(test_urls)
        print(f"\nğŸ“Š æè‡´å¹¶è¡ŒV3ç»“æœ: {v3_time:.2f}ç§’")
        
        # æ€§èƒ½å¯¹æ¯”
        print("\n" + "="*50)
        print("ğŸ† æè‡´å¹¶è¡Œæ€§èƒ½å¯¹æ¯”:")
        print(f"   é¢„åˆå§‹åŒ–å…±äº«å®¢æˆ·ç«¯: {v1_time:.2f}ç§’")
        print(f"   create_taskå¯åŠ¨:   {v2_time:.2f}ç§’")
        print(f"   åŸå§‹httpxå¹¶å‘:     {v3_time:.2f}ç§’")
        
        best_time = min(v1_time, v2_time, v3_time)
        print(f"\nğŸ¥‡ æœ€ä½³æ€§èƒ½: {best_time:.2f}ç§’")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main())